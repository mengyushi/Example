{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from dnn_app_utils_v2 import *\n",
    "from image_input import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "train_x_orig, train_y = imput_training_set()\n",
    "test_x_orig, test_y = imput_testing_set()\n",
    "\n",
    "#classes = [b'non-concrete' b'concrete']\n",
    "\n",
    "m_train = train_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "m_test = test_x_orig.shape[0]\n",
    "\n",
    "# Reshape the training and test examples\n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1)   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1)\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "#print (\"train_x's shape: \" + str(train_x.shape))\n",
    "#print (\"test_x's shape: \" + str(test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### CONSTANTS DEFINING THE MODEL ####\n",
    "layers_dims = [12288, 20, 7, 5, 1] #  5-layer model\n",
    "\n",
    "# GRADED FUNCTION: 5_layer_model\n",
    "\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate = 0.01, num_iterations = 5000, print_cost=False):#lr was 0.009\n",
    "    \"\"\"\n",
    "    Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "\n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "\n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "    costs = []                         # keep track of cost\n",
    "\n",
    "    # Parameters initialization.\n",
    "    ### START CODE HERE ###\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Loop (gradient descent)\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: [LINEAR -> RELU]*(L-1) -> LINEAR -> SIGMOID.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Compute cost.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Backward propagation.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Update parameters.\n",
    "        ### START CODE HERE ### (≈ 1 line of code)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.588359\n",
      "Cost after iteration 100: 0.404895\n",
      "Cost after iteration 200: 0.361070\n",
      "Cost after iteration 300: 0.324773\n",
      "Cost after iteration 400: 0.293557\n",
      "Cost after iteration 500: 0.265633\n",
      "Cost after iteration 600: 0.239605\n",
      "Cost after iteration 700: 0.214972\n",
      "Cost after iteration 800: 0.198181\n",
      "Cost after iteration 900: 0.175985\n",
      "Cost after iteration 1000: 0.156763\n",
      "Cost after iteration 1100: 0.258774\n",
      "Cost after iteration 1200: 0.142292\n",
      "Cost after iteration 1300: 0.139058\n",
      "Cost after iteration 1400: 0.114227\n",
      "Cost after iteration 1500: 0.098783\n",
      "Cost after iteration 1600: 0.088820\n",
      "Cost after iteration 1700: 0.153213\n",
      "Cost after iteration 1800: 0.088517\n",
      "Cost after iteration 1900: 0.142578\n",
      "Cost after iteration 2000: 0.120986\n",
      "Cost after iteration 2100: 0.060600\n",
      "Cost after iteration 2200: 0.057097\n",
      "Cost after iteration 2300: 0.054852\n",
      "Cost after iteration 2400: 0.052301\n",
      "Cost after iteration 2500: 0.049054\n",
      "Cost after iteration 2600: 0.046984\n",
      "Cost after iteration 2700: 0.045660\n",
      "Cost after iteration 2800: 0.043228\n",
      "Cost after iteration 2900: 0.041532\n",
      "Cost after iteration 3000: 0.039974\n",
      "Cost after iteration 3100: 0.038673\n",
      "Cost after iteration 3200: 0.037555\n",
      "Cost after iteration 3300: 0.036066\n",
      "Cost after iteration 3400: 0.034849\n",
      "Cost after iteration 3500: 0.033771\n"
     ]
    }
   ],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 5000, print_cost = True)\n",
    "\n",
    "print(\"Train data:\")\n",
    "pred_train = predict(train_x, train_y, parameters)\n",
    "print(\"Test data:\")\n",
    "pred_test = predict(test_x, test_y, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now Testing my_image\n",
      "Accuracy: 1.0\n",
      "my_image's Prediction: [[ 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Now Testing my_image\")\n",
    "#My Picture\n",
    "## START CODE HERE ##\n",
    "my_image = \"my_image.jpg\" # change this to the name of your image file\n",
    "my_label_y = [1] # the true class of your image (1 -> cat, 0 -> non-cat)\n",
    "## END CODE HERE ##\n",
    "\n",
    "num_px=64\n",
    "\n",
    "fname = \"images_testing/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(num_px,num_px)).reshape((num_px*num_px*3,1))\n",
    "\n",
    "#print(my_image.shape)\n",
    "my_predicted_image = predict(my_image, my_label_y, parameters)\n",
    "print(\"my_image's Prediction:\",my_predicted_image)\n",
    "#plt.imshow(image)\n",
    "#print (\"y = \" + str(np.squeeze(my_predicted_image)) + \", your L-layer model predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
